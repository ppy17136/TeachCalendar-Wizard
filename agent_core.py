import streamlit as st
import json
import time
from llm_wrapper import ai_generate
from skills import SyllabusSkills

class AgentCore:
    def __init__(self, keys_config, provider="Gemini", model_name="gemini-1.5-pro"):
        self.keys_config = keys_config
        self.provider = provider
        self.model_name = model_name
        self.skills = SyllabusSkills(keys_config, model_name)
        self.history = []
        
    def log(self, message):
        """Output to Streamlit UI or Console"""
        if "agent_logs" not in st.session_state:
            st.session_state.agent_logs = []
        st.session_state.agent_logs.append(message)
        # Using st.write directly might break if not in correct context, usually handled by caller
        
    def run_syllabus_generation(self, user_inputs, uploaded_texts):
        """
        Orchestrates the syllabus generation process (thinking + tool execution)
        Outputs: Structed JSON for rendering
        """
        yield "ğŸ¤– Agent å¯åŠ¨: æ­£åœ¨åˆå§‹åŒ–å¤§çº²ç”Ÿæˆä»»åŠ¡..."
        
        # 1. Check for Training Plan PDF to extract Matrix
        graduation_matrix_context = "æœªæä¾›åŸ¹å…»æ–¹æ¡ˆï¼Œéœ€æ ¹æ®é€šç”¨æ ‡å‡†æ¨å¯¼ã€‚"
        if "plan_file_path" in user_inputs and user_inputs["plan_file_path"]:
             yield "ğŸ” æ­£åœ¨æ·±å…¥è§£æåŸ¹å…»æ–¹æ¡ˆPDF (å¯»æ‰¾æ¯•ä¸šè¦æ±‚æ”¯æ’‘çŸ©é˜µ)..."
             matrix_data = self.skills.extract_graduation_matrix(user_inputs["plan_file_path"])
             graduation_matrix_context = f"ä»PDFæå–çš„æ”¯æ’‘çŸ©é˜µæ•°æ®ï¼ˆè¯·ä¸¥æ ¼æ®æ­¤ç”Ÿæˆï¼‰ï¼š\n{matrix_data[:3000]}" # Limit size
        
        # 2. Construct the "System 2" Prompt (JSON Schema Enforcement)
        system_prompt = f"""
        # è§’è‰²
        ä½ æ˜¯ä¸€ä½å·¥ç¨‹æ•™è‚²è®¤è¯ï¼ˆOBEï¼‰ä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„è¯¾ç¨‹ä¿¡æ¯å’Œå‚è€ƒèµ„æ–™ï¼Œç”Ÿæˆä¸€ä»½æ ‡å‡†çš„æ•™å­¦å¤§çº²ã€‚
        
        # æ ¸å¿ƒæŒ‡ä»¤
        **å¿…é¡»è¾“å‡ºç¬¦åˆä»¥ä¸‹ Schema çš„çº¯ JSON æ ¼å¼æ•°æ®**ã€‚ä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ã€‚
        
        # JSON Schema å®šä¹‰
        {{
            "course_name": "{user_inputs.get('name', 'æœªå‘½å')}",
            "base_info": {{
                "name": "{user_inputs.get('name', 'æœªå‘½å')}", 
                "code": "BJxxxx", 
                "credits": {user_inputs.get('credits', 0)}, 
                "hours": {user_inputs.get('hours', 0)},
                "type": "{user_inputs.get('course_type', 'å¿…ä¿®')}", 
                "major": "{user_inputs.get('major', 'æœªå®š')}", 
                "prerequisites": "å…ˆä¿®è¯¾"
            }},
            "objectives": ["ç›®æ ‡1", "ç›®æ ‡2", "..."],
            "grad_support": [
                {{ "req": "æ¯•ä¸šè¦æ±‚1", "point": "1.3 å·¥ç¨‹çŸ¥è¯†", "strength": "H" }},
                {{ "req": "æ¯•ä¸šè¦æ±‚3", "point": "3.2 è®¾è®¡/å¼€å‘", "strength": "M" }}
            ],
            "content": [
                {{ "chapter": "ç¬¬ä¸€ç«  ç»ªè®º", "details": "...å†…å®¹...", "lec_hrs": 2, "lab_hrs": 0, "obj_ref": "ç›®æ ‡1" }}
            ],
            "assessment": "å¹³æ—¶æˆç»©30%...",
            "textbook": "æ•™æåŠå‚è€ƒä¹¦..."
        }}
        
        # å…³é”®å‚è€ƒèµ„æ–™
        1. è¯¾ç¨‹åŸºæœ¬ä¿¡æ¯ï¼š{json.dumps(user_inputs, ensure_ascii=False)}
        2. æ•™æè¾…åŠ©å†…å®¹ï¼š{uploaded_texts.get('textbook', '')[:2000]}
        3. æ¯•ä¸šè¦æ±‚çŸ©é˜µæ•°æ®ï¼š{graduation_matrix_context}
        
        # æ€è€ƒæ­¥éª¤
        1. **åˆ†æçŸ©é˜µ**ï¼šä»”ç»†é˜…è¯»â€œæ¯•ä¸šè¦æ±‚çŸ©é˜µæ•°æ®â€ï¼Œæ‰¾å‡ºæœ¬è¯¾ç¨‹å¯¹åº”çš„æ‰€æœ‰â€œæ¯•ä¸šè¦æ±‚æŒ‡æ ‡ç‚¹â€å’Œâ€œæ”¯æ’‘å¼ºåº¦â€ã€‚å¦‚æœæ•°æ®ä¸­æœ‰ï¼Œå¿…é¡»ä¸¥æ ¼ç…§æ¬ï¼Œ**ä¸¥ç¦ç¼–é€ **ã€‚
        2. **è®¾è®¡ç›®æ ‡**ï¼šæ ¹æ®æ”¯æ’‘çš„æŒ‡æ ‡ç‚¹ï¼Œåæ¨3-5ä¸ªè¯¾ç¨‹ç›®æ ‡ã€‚
        3. **è§„åˆ’å†…å®¹**ï¼šæ ¹æ®æ€»å­¦æ—¶ ({user_inputs.get('hours', 0)}) åˆ†é…ç« èŠ‚ã€‚
        """
        
        yield "ğŸ§  æ­£åœ¨è¿›è¡Œ OBE é€†å‘è®¾è®¡ (æŒ‡æ ‡ç‚¹ -> è¯¾ç¨‹ç›®æ ‡)..."
        
        # 3. Call LLM (First Pass for JSON)
        try:
            raw_response = ai_generate(system_prompt, self.provider, self.model_name, self.keys_config)
            
            # 4. Clean and Parse JSON
            yield "ğŸ“ æ­£åœ¨ç»„è£…ç»“æ„åŒ–å¤§çº²æ•°æ®..."
            json_str = raw_response.strip()
            # Remove ```json only if present
            if json_str.startswith("```"):
                json_str = json_str.strip("`").replace("json", "", 1).strip()
            
            syllabus_data = json.loads(json_str)
            
            # Yield the final result data wrapper
            yield {"final_result": syllabus_data}
            yield "âœ… ç»“æ„åŒ–å¤§çº²ç”Ÿæˆå®Œæˆï¼"
            
        except json.JSONDecodeError:
            yield "âŒ ç”Ÿæˆçš„ JSON æ ¼å¼æœ‰è¯¯ï¼Œæ­£åœ¨è¿›è¡Œ Markdown é™çº§å¤„ç†..."
            # Failover: Return raw text wrapped in pseudo-structure so UI doesn't crash
            yield {"final_result": {"doc_type": "raw_markdown", "content": raw_response}}
        except Exception as e:
            yield f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
            return

